{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc4f8f34",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10180242",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lorinctoldi/deep-learning/blob/main/main.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2175ca04",
   "metadata": {},
   "source": [
    "#### Source\n",
    "The Container Ship Dataset is publicly available on [Kaggle](https://www.kaggle.com/c/airbus-ship-detection) and was created for the Airbus Ship Detection Challenge. It is designed for maritime object detection and segmentation tasks using satellite imagery.\n",
    "\n",
    "##### Dataset Overview\n",
    "- Source: Kaggle, Airbus Ship Detection Challenge\n",
    "- Size of dataset: ~32 Gb\n",
    "- Number of images: ~193,000\n",
    "- Image resolution: 768 × 768 pixels (RGB)\n",
    "- Annotations: Run-Length Encoded (RLE) masks for each ship\n",
    "- Empty images: Some images contain no ships\n",
    "- Multiple ships per image: Many images have more than one ship, each represented by a separate RLE (one-to-many)\n",
    "\n",
    "##### Dataset Structure\n",
    "The annotations are provided as a CSV file (segmentations.csv) with columns:\n",
    "\n",
    "| Column          | Description                                   |\n",
    "|-----------------|-----------------------------------------------|\n",
    "| `ImageId`       | Image filename                                |\n",
    "| `EncodedPixels` | RLE mask for a single ship (empty if none)    |\n",
    "\n",
    "- Images with multiple ships appear multiple times in the CSV.\n",
    "- Empty `EncodedPixels` indicates no ships in that image.\n",
    "\n",
    "##### Kaggle Data Folders, Files\n",
    "- `test_v2/` – Test images.\n",
    "- `train_v2/` – Training images.\n",
    "- `train_ship_segmentations_v2.csv`- CSV file containing image IDs and their corresponding RLE-encoded ship masks.\n",
    "- `sample_submission_v2.csv` - Template submission file listing image IDs from the test_v2 folder with empty EncodedPixels fields to be filled by model predictions.\n",
    "\n",
    "We exclude `test_v2` and `sample_submission_v2.csv` because they contain no labels and would require manual evaluation of predictions.\n",
    "\n",
    "##### Data Folders, Files\n",
    "- `cache/` – Precomputed or heavy computation outputs (e.g., cached mask analyses).\n",
    "- `assets/` – Contains images and figures used for demonstrations or visual references within the notebooks.\n",
    "- `data/images/` – Raw images from the dataset.\n",
    "- `original_segmentations.csv` – Pre-cleaned RLE CSVs for initial data exploration.\n",
    "- `segmentations.csv` – Cleaned segmentation CSVs (problematic masks handled)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d1b58",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e970c",
   "metadata": {},
   "source": [
    "To download the dataset, Kaggle requires users to **be signed in and to have joined the competition**. Since our workflow involves removing some of the original Kaggle folders and renaming the remaining ones, we implemented scripts to automate and simplify the setup process.\n",
    "\n",
    "Initially, we attempted to use the official Kaggle API. However, the API attempts to **load the entire dataset into memory** before writing it to a ZIP file, which is inefficient and impractical for a dataset of approximately 30 GB.\n",
    "\n",
    "We also considered hosting the dataset on **Google Cloud Storage and Amazon S3**. However, after estimating the potential usage of 10–20 downloads per month, the expected monthly cost ranged between **50 USD and 80 USD**, making these options financially impractical for our project.\n",
    "\n",
    "As an alternative, we uploaded the required ZIP archive to **Google Drive and used the `gdown`** library to automate the download. Because Google Drive enforces download **quota limits**, we uploaded the same file 2 times and created a script that sequentially attempts each mirror link.\n",
    "\n",
    "Despite this workaround, download failures may still occur due to quota restrictions. In such cases, a **manual download procedure is provided** as a fallback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7665b46a",
   "metadata": {},
   "source": [
    "##### Automated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50df2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_links = [\n",
    "    \"https://drive.google.com/uc?id=1C9VNNb7-LHF82Err00i64KHBJyraw4HX\",\n",
    "    \"https://drive.google.com/uc?id=1IWnW8id-noLM4EUnK99CBNn932waieQe\",\n",
    "]\n",
    "\n",
    "output_path = \"./data.zip\"\n",
    "\n",
    "def download_with_fallback(mirrors: list[str], output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Try downloading from each Google Drive mirror sequentially.\n",
    "    Stops immediately after the first successful download.\n",
    "    \n",
    "    :param mirrors: List of Google Drive URLs.\n",
    "    :param output_path: Path to save the downloaded file.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    for i, url in enumerate(mirrors, start=1):\n",
    "        print(f\"\\nAttempt {i}/{len(mirrors)}: {url}\")\n",
    "        try:\n",
    "            result = gdown.download(url, output_path, quiet=False)\n",
    "            if result:\n",
    "                print(f\"\\nSuccessfully downloaded to: {output_path}\")\n",
    "                return\n",
    "            else:\n",
    "                print(\"Download failed, trying next mirror...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during download: {e}\")\n",
    "\n",
    "    print(\"\\nAll mirrors failed. Please download manually.\")\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    download_with_fallback(drive_links, output_path)\n",
    "else:\n",
    "    print(f\"{output_path} already exists, skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c32a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ca6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = \"./data.zip\"\n",
    "extract_to = \"./data\"\n",
    "\n",
    "os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "images_folder = os.path.join(extract_to, \"images\")\n",
    "\n",
    "if not os.path.exists(images_folder):\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    print(\"Data extracted.\")\n",
    "else:\n",
    "    print(\"Images folder already exists — skipping extraction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87948639",
   "metadata": {},
   "source": [
    "##### Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f175e",
   "metadata": {},
   "source": [
    "If the automated download script fails because of Google Drive quota limits, you can obtain the dataset manually by following the steps below or by directly opening the Google Drive links provided in the code block above.\n",
    "\n",
    "1. Navigate to the [Airbus Ship Detection Challenge dataset on Kaggle](https://www.kaggle.com/competitions/airbus-ship-detection/data).  \n",
    "2. **Sign in** to your Kaggle account or **register** if you don’t have one.  \n",
    "3. **Join the competition** to gain access to the dataset.  \n",
    "\n",
    "   ![](assets/1.png)\n",
    "\n",
    "4. Click on **`train_ship_segmentations_v2.csv`** and press **Download** in the top-right corner.  \n",
    "\n",
    "   ![](assets/2.png)\n",
    "\n",
    "5. Click on **`train_v2`** and press **Download** in the top-right corner.  \n",
    "\n",
    "   ![](assets/3.png)\n",
    "\n",
    "6. **Unzip** both downloaded files and move the extracted CSV file and folder into the `data/` directory of this repository. \n",
    "7. Rename the file **`train_ship_segmentations_v2.csv`** to **`original_segmentations.csv`**.  \n",
    "8. Rename the folder **`train_v2`** to **`images`**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd91974",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e304b933",
   "metadata": {},
   "source": [
    "##### Validation Criteria\n",
    "- Each RLE mask should correspond to a single boat, which is treated as a closed object. Consequently, every mask is expected to contain exactly one connected shape of reasonable size.\n",
    "\n",
    "##### Methodology\n",
    "1. Read in the segmentation CSV file.\n",
    "2. Convert each RLE mask into a 2D binary mask.\n",
    "3. For images with an RLE annotation, count the number of connected shapes in the mask and measure their sizes in pixels.\n",
    "4. If a mask contains more than one shape or no shape reaches at least 12 pixels, mark it as problematic.\n",
    "5. Visualize problematic images by displaying the image with the mask overlaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f52028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7170f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7871d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_masks(original = True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26454b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_2d_mask_from_rle\n",
    "from utils import get_number_of_shapes_and_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86682116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def analyze_shapes_in_masks(masks_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute number of shapes and their sizes for each image RLE mask. \n",
    "    Skips any rows where 'EncodedPixels' is empty. \n",
    "    \n",
    "    :param masks_df: DataFrame with columns 'ImageId' and 'EncodedPixels' \n",
    "    :return: DataFrame with columns 'ImageId', 'num_shapes', and 'shape_sizes' \n",
    "    \"\"\" \n",
    "    results = []\n",
    "    for index, row in tqdm(masks_df.iterrows(), total=len(masks_df), desc=\"Analyzing masks\"): \n",
    "        if not row.EncodedPixels: \n",
    "            continue\n",
    "\n",
    "        mask = get_2d_mask_from_rle(row.EncodedPixels) \n",
    "        sizes = get_number_of_shapes_and_sizes(mask) \n",
    "\n",
    "        results.append({\n",
    "            \"index\": index,\n",
    "            \"image_id\": row.ImageId,\n",
    "            \"num_shapes\": len(sizes), \n",
    "            \"shape_sizes\": sizes, \n",
    "        }) \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import use_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91130562",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = load_masks(original = True)\n",
    "shapes = use_cache(analyze_shapes_in_masks)(masks)\n",
    "\n",
    "num_images = shapes[\"image_id\"].nunique()\n",
    "print(f\"Number of images analyzed: {num_images}\")\n",
    "\n",
    "mean_shapes = shapes[\"num_shapes\"].mean()\n",
    "min_shapes = shapes[\"num_shapes\"].min()\n",
    "max_shapes = shapes[\"num_shapes\"].max()\n",
    "print(f\"Number of shapes per image -> mean: {mean_shapes:.2f}, min: {min_shapes}, max: {max_shapes}\")\n",
    "\n",
    "all_sizes = [s for sizes in shapes[\"shape_sizes\"] for s in sizes]\n",
    "print(f\"Shape sizes -> mean: {np.mean(all_sizes):.2f}, min: {min(all_sizes)}, max: {max(all_sizes)}\")\n",
    "\n",
    "shapes_sorted = shapes.sort_values(by=\"num_shapes\", ascending=False)\n",
    "shapes_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f88cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import visualize_image_with_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import MIN_SHAPE_SIZE\n",
    "\n",
    "problematic_shapes = shapes[\n",
    "    (shapes[\"num_shapes\"] > 1) |\n",
    "    (shapes[\"shape_sizes\"].apply(lambda sizes: all(s < MIN_SHAPE_SIZE for s in sizes)))\n",
    "]\n",
    "\n",
    "print(f\"Number of problematic shapes: {len(problematic_shapes)}\")\n",
    "print(f\"Percentage problematic shapes: {len(problematic_shapes)/len(shapes)*100:.2f}%\\n\")\n",
    "\n",
    "problematic_shapes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2019d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_problematic_shapes(\n",
    "    problematic_shapes: pd.DataFrame,\n",
    "    masks_df: pd.DataFrame,\n",
    "    n_images: int = 3\n",
    "):\n",
    "    \"\"\"\n",
    "    Randomly display problematic images (images with more than one shape).\n",
    "\n",
    "    :param problematic_shapes: DataFrame containing problematic mask information, returned by `analyze_shapes_in_masks()`\n",
    "    :param masks_df: Original masks DataFrame with columns 'ImageId' and 'EncodedPixels'\n",
    "    :param n_images: Number of random problematic images to display (default is 3)\n",
    "    \"\"\"\n",
    "    if problematic_shapes.empty:\n",
    "        print(\"No problematic images found!\")\n",
    "        return\n",
    "\n",
    "    n_images = min(n_images, len(problematic_shapes))\n",
    "    sampled_rows = problematic_shapes.sample(n=n_images)\n",
    "\n",
    "    for i, row in sampled_rows.iterrows():\n",
    "        original_index = row[\"index\"]\n",
    "        mask_row = masks_df.iloc[original_index]\n",
    "\n",
    "        mask = get_2d_mask_from_rle(mask_row.EncodedPixels)\n",
    "\n",
    "        print(f\"\\n--- Problematic Image {i+1} ---\")\n",
    "        print(f\"ImageId: {mask_row.ImageId}\")\n",
    "        print(f\"Number of shapes: {row.num_shapes}\")\n",
    "        print(f\"Shape sizes: {row.shape_sizes}\")\n",
    "\n",
    "        visualize_image_with_mask(mask_row.ImageId, mask)\n",
    "\n",
    "analyze_problematic_shapes(problematic_shapes, masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91181a2",
   "metadata": {},
   "source": [
    "##### Validation Criteria\n",
    "- Masks should not overlap, as two boats cannot occupy the same physical space in the image.\n",
    "\n",
    "##### Methodology\n",
    "1. Read in the segmentation CSV file.\n",
    "2. Convert each RLE mask into a 2D binary mask.\n",
    "3. Check for overlapping shapes across all masks of the same image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import rles_to_combined_mask, has_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47cff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from constants import SHAPE\n",
    "\n",
    "def analyze_mask_overlaps(masks_df: pd.DataFrame, shape = SHAPE) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze whether masks for each image overlap.\n",
    "\n",
    "    :param masks_df: DataFrame containing mask RLEs with columns 'ImageId' and 'EncodedPixels'\n",
    "    :param shape: Tuple of (height, width) specifying the dimensions of the 2D masks\n",
    "    :return: DataFrame with columns 'image_id' and 'has_overlap' (True/False)\n",
    "    \"\"\"\n",
    "    grouped = masks_df.groupby(\"ImageId\")\n",
    "    results = []\n",
    "\n",
    "    for image_id, group in tqdm(grouped, desc=\"Analyzing masks\"):\n",
    "        rle_list = group[\"EncodedPixels\"].tolist()\n",
    "\n",
    "        combined_mask = rles_to_combined_mask(rle_list, shape)\n",
    "        overlap = has_overlap(combined_mask)\n",
    "\n",
    "        results.append({\n",
    "            \"image_id\": image_id,\n",
    "            \"has_overlap\": overlap,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = load_masks(original = True, filter_empty = True)\n",
    "overlaps = use_cache(analyze_mask_overlaps)(masks)\n",
    "\n",
    "total_images = len(overlaps)\n",
    "num_overlaps = overlaps[\"has_overlap\"].sum()\n",
    "percent_overlaps = num_overlaps / total_images * 100\n",
    "\n",
    "print(f\"Total images analyzed (with masks): {total_images}\")\n",
    "print(f\"Number of images with overlapping masks: {num_overlaps}\")\n",
    "print(f\"Percentage of overlapping images: {percent_overlaps:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc7364a",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea56792",
   "metadata": {},
   "source": [
    "##### Methodology\n",
    "- Remove masks with no valid shapes: If a mask contains no shapes larger than 12 pixels, discard the mask entirely.  \n",
    "- Keep only the largest shape: For masks with multiple shapes, remove all shapes except the largest one to ensure each mask corresponds to a single boat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de85c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import keep_largest_shape, get_rle_from_2d_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd09fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = load_masks(original = True)\n",
    "shapes = use_cache(analyze_shapes_in_masks)(masks)\n",
    "\n",
    "problematic_images = shapes[\n",
    "    (shapes[\"num_shapes\"] > 1) |\n",
    "    (shapes[\"shape_sizes\"].apply(lambda sizes: all(s < MIN_SHAPE_SIZE for s in sizes)))\n",
    "]\n",
    "\n",
    "for _, row in problematic_images.iterrows():\n",
    "    original_index = row[\"index\"]\n",
    "    mask_row = masks.iloc[original_index]\n",
    "\n",
    "    mask = get_2d_mask_from_rle(mask_row.EncodedPixels)\n",
    "\n",
    "    if all(s < MIN_SHAPE_SIZE for s in row.shape_sizes):\n",
    "        masks.at[original_index, \"EncodedPixels\"] = \"\"\n",
    "\n",
    "    else:\n",
    "        cleaned_mask = keep_largest_shape(mask)\n",
    "        new_rle = get_rle_from_2d_mask(cleaned_mask)\n",
    "        masks.at[original_index, \"EncodedPixels\"] = new_rle\n",
    "\n",
    "masks.to_csv(\"./data/segmentations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b3de9c",
   "metadata": {},
   "source": [
    "## Train, Test, Validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7284c7f1",
   "metadata": {},
   "source": [
    "##### Methodology\n",
    "\n",
    "The dataset is partitioned into training, validation, and test subsets using the following split:\n",
    "\n",
    "- **80%** validation\n",
    "- **10%** test\n",
    "- **10%** training\n",
    "\n",
    "As discussed in class, the data order is randomized prior to splitting to ensure an unbiased distribution across subsets.\n",
    "\n",
    "We initially considered adding a column to `segmentations.csv` to mark each row with its assigned subset. However, this step was deemed unnecessary, as the partitioning process will be handled using the `scikit-learn` library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
